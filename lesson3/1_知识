
1. 程序局部性原理:
    程序一旦装载进内存中, 地址就已经确定了
    同时, 程序可以分为两大类.
    代码 and数据
    cpu 的寄存器 也有两类 : 指令寄存器 and 数据寄存器


=====================================
程序局部性原理: 
    解释:
    也就是说，CPU 大多数时间在访问相同或者与此相邻的地址，
    换句话说就是：
    CPU 大多数时间在执行相同的指令或者与此相邻的指令。
    这就是大名鼎鼎的程序局部性原理。
=====================================


===========================================
    分割: 后续采用课程的知识点
    ,另外补充一片小林图解



拓展: 南北桥:
    南桥: 即系统I/O芯片（SI/O）：主要管理中低速外部设备；集成了中断控制器、DMA控制器。
    北桥: 系统控制芯片，主要负责CPU与内存、CPU与PCI-E之间的通信。掌控项目多为高速设备，
            如：CPU、Host Bus。后期北桥集成了内存控制器、Cache高速控制器。
        ==> 北桥 已经逐渐被集成到了cpu内部





====================================================================
灵魂: 如何写出让CPU更快的代码:
    思想: 
        1. 遵从局部性原则,减少跳转指令
        2. 写出cache友好的代码
        3. 尽可能的写出  良好的if语句 : 分支预测功能

    方法:
        1、遵从80-20法则，程序80%的时间在运行20%或更少的代码，针对热代码进行优化，才容易产出效果；
        2、遵从 `数据访问` 的局部性法则，
                    ==>  按数据存放顺序访问内存效率远高于乱序访问内存效率，
                    ==>  也就是尽量帮助CPU做好数据Cache的预测工作。同样根据Cache大小，做好数据结构的优化工作，进行数据压缩或数据填充，也是提升Cache效率的好方式；
        3、遵从 `指令访问` 的局部性法则，减少跳转指令，
                    ==>  同样是尽量帮助CPU做好数据Cache的预测工作；
                    ==>  现代CPU都有一些预测功能【如分支预测】，
                    ==>  利用好CPU的这些功能，也会提升Cache命中率；
        4、避免计算线程在多个核心之间漂移，避免缓存重复加载，
                    ==>  可以绑定核心【物理核即可，不用到逻辑核】，提高效率；
        5、去除伪共享缓存：在多核环境下，减少多个核心对同一区域内存的读写并发操作，减少内存失效的情况的发生；
             ===开始跑题===
        6、合理提高进程优先级，减少进程间切换，可以变相提供Cache提速的效果
        7、关闭Swap，可以变相提供内存提速、Cache提速的效果；
        8、使用Intel自家的编译器，开启性能优化，很多时候可以提速运算效率；
                == gcc 编译器的优化很蠢,只会做非常保守的优化
        9、使用C语言，而不是更高级的语言，很多时候可以提速运算效率；
        10、直接使用昂贵的寄存器作为变量，可以变相提供加速效果；
====================================================================